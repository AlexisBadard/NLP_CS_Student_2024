# Paper Presentation Guidelines

Welcome to the Advance NLP Class for CS student. This is time for you to read the rules of the Paper Presentation! Your presentation will be a pivotal part of your final grade, constituting 50% of it. To ensure you excel, here are the guidelines:

## Presentation Duration

- **Time Limit:** You have a tight window of 15 minutes to present your paper. Succinctness is key, so focus on the essentials and maintain a pedagogical approach throughout.

## Grading Criteria

Your presentation will be graded based on the following criteria:

1. **Clarity/Pedagogy (out of 10):** How clearly you convey the material and how effectively you teach the concepts.
   
2. **Correctness (out of 10):** The accuracy and precision of your understanding and explanation of the paper's content.

3. **Bonus (+2):** If your presentation slides are exceptionally well-crafted and enhance the understanding of the material.

4. **Malus (-1):** When you go over the allocated time, you'll incur a penalty of -1.

## Presentation Schedule and Paper Links

1. **11/03:** [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781)
   
2. **18/03:** [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)
   
3. **25/03:** [ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators](https://arxiv.org/abs/2003.10555)
   
4. **08/04:** [Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks](https://arxiv.org/abs/1908.10084)
   
5. **15/04:** 
   - [Scaling Instruction-Finetuned Language Models](https://arxiv.org/abs/2210.11416)
   - [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)
   - [Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing](https://arxiv.org/abs/2107.13586)


6. **16/04:**
   - [Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
   - [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971)
   - [A Survey on Knowledge Distillation of Large Language Models](https://arxiv.org/abs/2402.13116)

## What you need to do?

### Register

Choose by group of N/10 the paper you would like to present by registering before tomorrow 12:00 PM and register on the [google sheet](https://docs.google.com/spreadsheets/d/1HBXlbCJDLCH0SRD5u3fSRGgxOw2iUZnTAsT6CdCGVO0/edit?usp=sharing)

### The day before the presentation:

Send me your presentation before 8.PM and update the link of the presentation in the google sheet.

## Let's goooo! 

Make sure to thoroughly prepare and deliver your presentation. Good luck!

